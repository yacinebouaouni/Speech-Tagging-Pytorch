{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WordTag",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-6qziA-ZvJo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch.nn import Embedding\n",
        "import torch.optim as optim "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2J7rkX9OcXy",
        "colab_type": "text"
      },
      "source": [
        "#1-Creating and preparing dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_e_ihYQlacRD",
        "colab_type": "code",
        "outputId": "4511261e-0c3d-423c-c9cd-34e3f5e4f708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# First we create the training data using some sentences and their word-tags\n",
        "\n",
        "training_data = [\n",
        "    (\"The cat ate the cheese\".lower().split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
        "    (\"She read that book\".lower().split(), [\"NN\", \"V\", \"DET\", \"NN\"]),\n",
        "    (\"The dog loves art\".lower().split(), [\"DET\", \"NN\", \"V\", \"NN\"]),\n",
        "    (\"The elephant answers the phone\".lower().split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
        "    (\"He looked at that animal\".lower().split(),[\"NN\",\"V\",\"DET\",\"DET\",\"NN\"])\n",
        "]\n",
        "\n",
        "training_data[0]"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['the', 'cat', 'ate', 'the', 'cheese'], ['DET', 'NN', 'V', 'DET', 'NN'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8OIA5RUaxNH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "outputId": "413c7087-27f3-4276-e990-2c48a27b7d25"
      },
      "source": [
        "#Now we create a dictionary of code for each tag \n",
        "\n",
        "tag2idx = {\"DET\": 0, \"NN\": 1, \"V\": 2}\n",
        "\n",
        "#Now we have to give for each word a unique index\n",
        "\n",
        "word2idx={}\n",
        "\n",
        "for words,tags in training_data:\n",
        "\n",
        "  for word in words:\n",
        "\n",
        "    if word not in word2idx:\n",
        "\n",
        "      word2idx[word]=len(word2idx)\n",
        "    \n",
        "print(\"dictionary of words:\"+str(word2idx))     "
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dictionary of words:{'the': 0, 'cat': 1, 'ate': 2, 'cheese': 3, 'she': 4, 'read': 5, 'that': 6, 'book': 7, 'dog': 8, 'loves': 9, 'art': 10, 'elephant': 11, 'answers': 12, 'phone': 13, 'he': 14, 'looked': 15, 'at': 16, 'animal': 17}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFxZslICcRpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We must prepare the data in order to output a vector \n",
        "\n",
        "def prepare(sentense,idx=word2idx):\n",
        "\n",
        "  \"\"\"\n",
        "  This function takes a sentence/tags and returns a pytorch tensor of corresponding indexes to each word\n",
        "  \"\"\"\n",
        "  output=np.array([idx[word] for word in sentense])\n",
        "  output=torch.from_numpy(output)\n",
        "  return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRj-RSUdQEP8",
        "colab_type": "text"
      },
      "source": [
        "#2-Understanding the code of LSTM:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gljXyXhXi2Lo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm=nn.LSTM(input_size=4,hidden_size=6,)\n",
        "\"\"\"\n",
        "the input is a 3D tensor of shape (seq_len, batch, input_size)\n",
        "input_size :Number of features EX:in time series temperature,pressor,and weather informations in a specific time\n",
        "hidden_size:Number of hidden states (Neurones)\n",
        "By default the first state is set to 0 we can change it\n",
        "output, (h_n, c_n)\n",
        "    - **output** of shape `(seq_len, batch, num_directions * hidden_size)`: tensor  \n",
        "      containing the output features `(h_t)` from the last layer of the LSTM\n",
        "    -(h_n,c_n) is the short and long term memory of the LSTM\n",
        "\n",
        "\"\"\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NwpsnorsEgh",
        "colab_type": "text"
      },
      "source": [
        "# 3-Create Model for Word-Tagger:*texte en italique*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH9TPw1gsKRE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WordTagger(nn.Module):\n",
        "\n",
        "  def __init__(self,embedding_size,hidden_size,vocabulary_size,target_size):\n",
        "    \n",
        "    super(WordTagger,self).__init__()\n",
        "\n",
        "    self.hidden_dim=hidden_size\n",
        "\n",
        "    self.embedding=Embedding(vocabulary_size,embedding_size)\n",
        "    \n",
        "    self.lstm=nn.LSTM(input_size=embedding_size,hidden_size=hidden_size)\n",
        "\n",
        "    self.linear=nn.Linear(hidden_size,target_size)\n",
        "\n",
        "    self.hidden=self.init_hidden()\n",
        "\n",
        "  def init_hidden(self):\n",
        "\n",
        "    \"\"\"\n",
        "    The method initialize the hidden state of LSTM cells \n",
        "    Hidden state consists of 2 tensors of shape (num_layers * num_directions, batch, hidden_size)\n",
        "    \"\"\"\n",
        "    h0=torch.zeros(1,1,self.hidden_dim)\n",
        "    c0=torch.zeros(1,1,self.hidden_dim)\n",
        "    return (h0,c0)\n",
        "\n",
        "  def forward(self,sentence):\n",
        "\n",
        "    embed=self.embedding(sentence)\n",
        "    embed=embed.view(len(sentence),1,-1) #Add the batch size to the size of the input\n",
        "    lstm_out,self.hidden=self.lstm(embed,self.hidden)\n",
        "    outputs=self.linear(lstm_out.view(len(sentence),-1))\n",
        "    tags_scores=F.log_softmax(outputs,dim=1) #the softmax will be computed accros 1 which means for each word (not sequence)\n",
        "    \n",
        "    return tags_scores\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOG94r5L2iuP",
        "colab_type": "text"
      },
      "source": [
        "#4-Define the Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWDcaUoJ1SQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_size=6 #Encode each word in 6 dimensional vector\n",
        "hidden_size=5\n",
        "target_size=len(tag2idx) #we have 3 tags\n",
        "vocabulary_size=len(word2idx)\n",
        "\n",
        "Model=WordTagger(embedding_size,hidden_size,vocabulary_size,target_size)\n",
        "\n",
        "loss_function=nn.NLLLoss() #Since our LSTM outputs a series of tag scores with a softmax layer, we will use NLLLoss\n",
        "optimizer=optim.SGD(Model.parameters(),lr=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnA9Mkpt8IuQ",
        "colab_type": "text"
      },
      "source": [
        "#5-Train the Model:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH8kpBzk8L9q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "bbced421-c771-4ded-cf0f-1a4209097f2f"
      },
      "source": [
        "epochs=300\n",
        "\n",
        "for e in range(epochs):\n",
        "\n",
        "  epoch_loss=0.0\n",
        "\n",
        "  for sentence,tags in training_data:\n",
        "\n",
        "    Model.hidden = Model.init_hidden() #This will detach the model from its history each sentence is independent\n",
        "\n",
        "    sentence=prepare(sentence,word2idx)\n",
        "    tags=prepare(tags,tag2idx)\n",
        "\n",
        "    \n",
        "    \n",
        "    predicted_tags=Model(sentence)\n",
        "    \n",
        "\n",
        "    #assert predicted_tags.size()==tags.size(),\"Error in the size of tags\"\n",
        "    \n",
        "    \n",
        "    Model.zero_grad()\n",
        "\n",
        "    loss=loss_function(predicted_tags,tags)\n",
        "\n",
        "    epoch_loss+=loss.item()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "  if e%20==19:\n",
        "\n",
        "    print(\"epoch:{} ,loss = {} \".format(e+1,epoch_loss/len(training_data))) #We print the mean loss for the words\n"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:20 ,loss = 1.0291601777076722 \n",
            "epoch:40 ,loss = 0.9433849334716797 \n",
            "epoch:60 ,loss = 0.7052922964096069 \n",
            "epoch:80 ,loss = 0.3633378207683563 \n",
            "epoch:100 ,loss = 0.1720342755317688 \n",
            "epoch:120 ,loss = 0.09648850858211518 \n",
            "epoch:140 ,loss = 0.06288489252328873 \n",
            "epoch:160 ,loss = 0.04526218958199024 \n",
            "epoch:180 ,loss = 0.03478707931935787 \n",
            "epoch:200 ,loss = 0.027976383827626704 \n",
            "epoch:220 ,loss = 0.02324918545782566 \n",
            "epoch:240 ,loss = 0.0198029525578022 \n",
            "epoch:260 ,loss = 0.017193349823355675 \n",
            "epoch:280 ,loss = 0.015156717039644718 \n",
            "epoch:300 ,loss = 0.013527943752706051 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utwc9tA7VjaJ",
        "colab_type": "text"
      },
      "source": [
        "#6-Testing the Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKfUA0H4LZNA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7d94bb80-dc45-4503-e67e-3790321855c7"
      },
      "source": [
        "test_sentence = \"she loves cheese\".lower().split()\n",
        "\n",
        "# see what the scores are after training\n",
        "inputs = prepare(test_sentence, word2idx)\n",
        "tag_scores = Model(inputs)\n",
        "print(tag_scores)\n",
        "\n",
        "# print the most likely tag index, by grabbing the index with the maximum score!\n",
        "# recall that these numbers correspond to tag2idx = {\"DET\": 0, \"NN\": 1, \"V\": 2}\n",
        "_, predicted_tags = torch.max(tag_scores, 1)\n",
        "print('\\n')\n",
        "print('Predicted tags: \\n',predicted_tags)\n",
        "test={0:\"DET\",1:\"NN\",2:\"V\"}\n",
        "for id,word in enumerate(test_sentence):\n",
        "  \n",
        "  print('Word:{} ,Predicted Tag : {} ==> {} '.format(word,predicted_tags[id],test[predicted_tags[id].item()]))"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-5.8063, -0.0071, -5.4951],\n",
            "        [-4.3214, -5.2606, -0.0186],\n",
            "        [-1.5231, -0.5951, -1.4678]], grad_fn=<LogSoftmaxBackward>)\n",
            "\n",
            "\n",
            "Predicted tags: \n",
            " tensor([1, 2, 1])\n",
            "Word:she ,Predicted Tag : 1 ==> NN \n",
            "Word:loves ,Predicted Tag : 2 ==> V \n",
            "Word:cheese ,Predicted Tag : 1 ==> NN \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}